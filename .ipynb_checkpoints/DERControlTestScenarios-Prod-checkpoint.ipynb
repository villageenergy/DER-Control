{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from boto3.session import Session\n",
    "from io import StringIO\n",
    "import random, boto3, pprint, datetime, sagemaker, time, ast\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucketName = 'testsmdata2'\n",
    "prefix = 'DERTestData/'\n",
    "kineisDestinationStream = \"DEROutputStream\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arn:aws:iam::440616111601:role/service-role/AmazonSageMaker-ExecutionRole-20200522T141912'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_df_to_csv(bkt, prefix, f_name, df):\n",
    "\n",
    "    \"\"\"\n",
    "    Writes the results on s3\n",
    "    \"\"\"\n",
    "\n",
    "    path='{}{}'.format(prefix,f_name)\n",
    "    print(f'{path}\\n')\n",
    "\n",
    "    csv_buffer = StringIO()\n",
    "    df.to_csv(csv_buffer, index=False)\n",
    "\n",
    "    s3_resource = boto3.client('s3')\n",
    "    s3_resource.put_object(Body=csv_buffer.getvalue(), Bucket=bkt,\n",
    "                           Key=path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readStreamData(DestinationStream):\n",
    "    client = boto3.client('kinesis')\n",
    "\n",
    "    shard_id = 'shardId-000000000000' #we only have one shard!\n",
    "    #shard_it = client.get_shard_iterator(StreamName=\"representativeDERResultStream\", ShardId=shard_id, ShardIteratorType=\"LATEST\")[\"ShardIterator\"]\n",
    "    ###shard_it = client.get_shard_iterator(StreamName=\"Veda5sMessage\", ShardId=shard_id, ShardIteratorType=\"LATEST\")[\"ShardIterator\"]\n",
    "    shard_it = client.get_shard_iterator(StreamName=DestinationStream, ShardId=shard_id, ShardIteratorType=\"LATEST\")[\"ShardIterator\"]\n",
    "\n",
    "\n",
    "    print('Waiting for data from DER ...')\n",
    "\n",
    "    records = []\n",
    "    while len(records) == 0:\n",
    "        out = client.get_records(ShardIterator=shard_it, Limit=2)\n",
    "        shard_it = out[\"NextShardIterator\"]\n",
    "        records = out['Records']\n",
    "        #print (records);\n",
    "        time.sleep(1)\n",
    "\n",
    "    #print(records)\n",
    "    recordDER = records[0]\n",
    "    recordNetwork = records[1]\n",
    "    #print('\\n', recordDER, '\\n', recordNetwork )\n",
    "    print('Data is ready ...')\n",
    "    return recordDER, recordNetwork\n",
    "\n",
    "#readStreamData(kineisDestinationStream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary2Dict(record):\n",
    "\n",
    "    byte_str = record['Data']\n",
    "    dict_str = byte_str.decode(\"UTF-8\")\n",
    "    data = ast.literal_eval(dict_str)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterRecords(Networkdata, DERdata):\n",
    "    Networkrecords = {}\n",
    "    for key in Networkdata.keys():\n",
    "        #print(key)\n",
    "        Networkrecords[key] = Networkdata[key]\n",
    "    #print(Networkrecords)    \n",
    "\n",
    "    Networkrecords.pop('DERstd10Sec', None)\n",
    "    Networkrecords.pop('DERstd30Sec', None)\n",
    "    Networkrecords.pop('DERstd1Min', None)\n",
    "    Networkrecords.pop('DERstd2Min', None)\n",
    "    Networkrecords.pop('DERstd5Min', None)\n",
    "\n",
    "    Networkrecords.pop('DEREnergy10Sec', None)\n",
    "    Networkrecords.pop('DEREnergy30Sec', None)\n",
    "    Networkrecords.pop('DEREnergy1Min', None)\n",
    "    Networkrecords.pop('DEREnergy2Min', None)\n",
    "    Networkrecords.pop('DEREnergy5Min', None)\n",
    "    #print(Networkrecords)\n",
    "    \n",
    "    DERrecords = {}\n",
    "    for key in DERdata.keys():\n",
    "        #print(key)\n",
    "        DERrecords[key] = DERdata[key]\n",
    "    #print(DERrecords)    \n",
    "    #records['TimeStamp'] = records['ApproximateArrivalTimestamp']\n",
    "\n",
    "    DERrecords.pop('Networkstd10Sec', None)\n",
    "    DERrecords.pop('Networkstd30Sec', None)\n",
    "    DERrecords.pop('Networkstd1Min', None)\n",
    "    DERrecords.pop('Networkstd2Min', None)\n",
    "    DERrecords.pop('Networkstd5Min', None)\n",
    "\n",
    "    DERrecords.pop('networkEnergy10Sec', None)\n",
    "    DERrecords.pop('networkEnergy30Sec', None)\n",
    "    DERrecords.pop('networkEnergy1Min', None)\n",
    "    DERrecords.pop('networkEnergy2Min', None)\n",
    "    DERrecords.pop('networkEnergy5Min', None)\n",
    "    #print(DERrecords)\n",
    "\n",
    "    records = {}\n",
    "    if DERrecords['eventTime'] == Networkrecords['eventTime']:\n",
    "        for key in DERrecords.keys():\n",
    "            records[key] = DERrecords[key]\n",
    "\n",
    "        for key in Networkrecords.keys():\n",
    "            records[key] = Networkrecords[key]\n",
    "    \n",
    "    return records\n",
    "\n",
    "#records = filterRecords(Networkdata, DERdata)\n",
    "#records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finalDataFrame(records, s, t):\n",
    "    df = pd.DataFrame(records, index=[0])\n",
    "    df ['state'] = s\n",
    "    df ['duration'] = t[0]\n",
    "    for timespan in ['10Sec', '30Sec', '1Min', '2Min', '5Min']:\n",
    "    #if (df['networkEnergy' + timespan])!=0:\n",
    "        df['pen' + timespan] = (1.5 * df['DEREnergy' + timespan]) / ((1.5 * df['DEREnergy' + timespan]) + df['networkEnergy' + timespan])\n",
    "    \n",
    "    for timespan in ['10Sec', '30Sec', '1Min', '2Min', '5Min']:\n",
    "        df = df.drop (columns = 'DEREnergy' + timespan)\n",
    "        df = df.drop (columns = 'networkEnergy' + timespan)\n",
    "        \n",
    "    df['eventTime'] = pd.to_datetime(df['eventTime']) + datetime.timedelta(hours = 5, minutes =30)\n",
    "    df['eventTime'] = df['eventTime'].apply(lambda x: x.strftime('%Y%m%dT%H%M%SZ')).astype(str)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 100\n",
    "\n",
    "durationTimes = [10, 20, 30, 60, 120]\n",
    "States = [[1, 1, 1, 1], \n",
    "          [0, 1, 1, 1],\n",
    "          [0, 0, 1, 1], \n",
    "          [0, 0, 0, 1]\n",
    "         ]\n",
    "\n",
    "duration = random.sample(durationTimes, 1)\n",
    "state = random.sample(States, 1)\n",
    "\n",
    "state , duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "start = timeit.default_timer() \n",
    "\n",
    "state , duration = [[1, 1, 1, 1]] , [0]\n",
    "i = 0\n",
    "dfAll = pd.DataFrame()\n",
    "\n",
    "for i in range (N):\n",
    "    \n",
    "    dfStage = pd.DataFrame()\n",
    "    i += 1\n",
    "    print (f'Sample Number {i} :')\n",
    "\n",
    "    try: \n",
    "        \n",
    "        print (f'State before sampling: {state} , {duration}')\n",
    "        recordDER, recordNetwork = readStreamData(kineisDestinationStream)\n",
    "    \n",
    "        DERdata, Networkdata = binary2Dict(recordDER), binary2Dict(recordNetwork)\n",
    "        records = filterRecords(Networkdata, DERdata)\n",
    "        dfBefore = finalDataFrame(records, state, duration)\n",
    "        sumStatesBefore = np.array(state).sum()\n",
    "        \n",
    "        state = random.sample(States, 1)\n",
    "        duration = random.sample(durationTimes, 1)\n",
    "        sumStatesAfter = np.array(state).sum()\n",
    "        \n",
    "        print (f'State after sampling: {state} , {duration}')\n",
    "        print ('Sending Command to DER ...')\n",
    "\n",
    "        # {Call the lambda function to send MQTT message to DER}\n",
    "        \n",
    "        if sumStatesAfter > sumStatesBefore:\n",
    "            time.sleep(180.0)    # 180 Ramp Up Time (Ping) \n",
    "        \n",
    "        time.sleep(int(duration[0]))  # duration[0] Wait Time \n",
    "\n",
    "        recordDER, recordNetwork = readStreamData(kineisDestinationStream)\n",
    "        \n",
    "        DERdata, Networkdata = binary2Dict(recordDER), binary2Dict(recordNetwork)\n",
    "        records = filterRecords(Networkdata, DERdata)\n",
    "        dfAfter = finalDataFrame(records, state , duration)\n",
    "\n",
    "\n",
    "        dfStage = pd.concat([dfBefore, dfAfter], axis=0)\n",
    "        fileName = 'DER_testStreamTransaction-' + dfAfter['eventTime'][0] + '.csv'\n",
    "        write_df_to_csv(bucketName, prefix, fileName, dfStage)\n",
    "        \n",
    "        dfAll = pd.concat([dfAll, dfStage], axis=0)\n",
    "        \n",
    "    except Exception as e: \n",
    "        \n",
    "        print (getattr(e, 'message', repr(e)))\n",
    "        continue \n",
    "\n",
    "fileName = 'DER_testStreamWholeExperimentTransaction-' + dfAfter['eventTime'][0] + '.csv'\n",
    "write_df_to_csv(bucketName, prefix, fileName, dfAll.reset_index())\n",
    "\n",
    "stop = timeit.default_timer()\n",
    "print('Running Time: ', stop - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfAll.reset_index()#[['state', 'duration']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
